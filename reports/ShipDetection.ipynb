{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "636f1461-5969-4b44-87fc-b91db7c22172",
   "metadata": {},
   "source": [
    "# Automation ship detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0e6ab319-357e-4136-b12d-c25f0628de12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "from typing import List, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "import re\n",
    "import folium\n",
    "from folium import plugins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "a988c6ee-c618-47b3-9c43-d34d0974992f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9f457a04-5fce-4f3d-a89a-26ed423b3b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------PARAMETERS----------\n",
    "# Assumed size of all cropped images\n",
    "IMAGE_SIZE = 80\n",
    "# Fixed size of the rough, proxy bounding box (e.g. 10 x 10 pixels)\n",
    "PROXY_BOX_SIZE = 10\n",
    "# Class ID for 'ship' in the detection model\n",
    "SHIP_CLASS_ID = 1\n",
    "OUTPUT_SIZE = 640\n",
    "\n",
    "# INPUT_PATH\n",
    "INPUT_PATH = \"/home/jsancheg/git_environment/CalEnvAgency/data/raw/shipdata_2025/cropped_ship_dataset\"\n",
    "# OUTPUT PATH\n",
    "OUTPUT_PATH = \"/home/jsancheg/git_environment/CalEnvAgency/data/processed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "77972e82-bec8-4d9e-aba6-a583586e1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def parse_filename(filename):\n",
    "  \"\"\"\n",
    "  Parse filename to extract metadata.\n",
    "  Format: {label}__{scene_id}__{longitude}_{latitude}.png\n",
    "  \"\"\"\n",
    "  try:\n",
    "    parts = filename.replace('.png','').split('__')\n",
    "    label = int(parts[0])\n",
    "    scene_id = parts[1]\n",
    "    coords = parts[2].split('_')\n",
    "    longitude = float(coords[0])\n",
    "    latitude = float(coords[1])\n",
    "    \n",
    "    return {\n",
    "    'filename': filename,\n",
    "    'label': label,\n",
    "    'label_name': 'ship' if label == 1 else 'no-ship',\n",
    "    'scene_id': scene_id,\n",
    "    'longitude': longitude,\n",
    "    'latitude': latitude\n",
    "    }\n",
    "  except Exception as e:\n",
    "    print(\"Error parsing {filename}: {e}\")\n",
    "    return None\n",
    "\n",
    "def load_dataset_metadata(dataset_path):\n",
    "  \"\"\"\n",
    "  Load and parse all image metadata from the dataset.\n",
    "  \"\"\"\n",
    "  print(\"=\"*88)\n",
    "  print(\"SHIP DETECTION DATASET - EXPLORATORY DATA ANALYSIS\")\n",
    "  print(\"=\"*88)\n",
    "  \n",
    "  image_files = [ f for f in os.listdir(dataset_path) if f.endswith('.png')]\n",
    "  metadata_list = []\n",
    "  total_files = len(image_files)\n",
    "\n",
    "  for filename  in image_files:\n",
    "    meta = parse_filename(filename)\n",
    "    if meta:\n",
    "      metadata_list.append(meta)\n",
    "\n",
    "  df = pd.DataFrame(metadata_list)\n",
    "  print(f\"\\n Successfully loaded {len(df)} inages from a total of {total_files}\")\n",
    "  return df\n",
    "\n",
    "def analyze_class_distribution(df):\n",
    "  \"\"\"\n",
    "  Analyze the distribution of ship vs no-ship classes\n",
    "  \"\"\"\n",
    "  \n",
    "  print(\"\\n\"+ \"=\"*80)\n",
    "  print(\"1. CLASS DISTRIBUTION ANALYSIS\")\n",
    "  print(\"=\"*80)\n",
    "  \n",
    "  class_counts = df['label_name'].value_counts()\n",
    "  print(f\"\\nClass Distribution:\")\n",
    "  \n",
    "  for label, count in class_counts.items():\n",
    "    percentage = (count / len(df)) * 100\n",
    "    print(f\"  {label:10s}:  {count:3d}  images  ({percentage:5.2f}%)\" )\n",
    "    \n",
    "  # Calculate class inbalance ratio\n",
    "  ship_count = class_counts.get('ship',0)\n",
    "  no_ship_count = class_counts.get('no-ship',0)\n",
    "  imbalance_ratio = max(ship_count, no_ship_count)/(min(ship_count, no_ship_count))\n",
    "  print(f\"\\nClass Imbalance Ratio: {imbalance_ratio:2f}:1\")\n",
    "  \n",
    "  if imbalance_ratio > 1.5:\n",
    "    print(\"Warning: Significant class imbalance detected\")\n",
    "    print(\"Recommendation: Considerar class weighting or data augmentation\")\n",
    "    \n",
    "  # Visualization\n",
    "  fig, axes = plt.subplots(1, 2, figsize = (14,5))\n",
    "  \n",
    "  # Bar chart\n",
    "  class_counts.plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'])\n",
    "  axes[0].set_title('Class_Distribution', fontsize = 14, fontweight = 'bold')\n",
    "  axes[0].set_xlabel('Class', fontsize = 12)\n",
    "  axes[0].set_ylabel('Number of Images', fontsize = 12)\n",
    "  axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation = 0)\n",
    "  axes[0].grid(axis='y', alpha = 0.3)\n",
    "  \n",
    "  # Pie chart\n",
    "  colors = ['#2ecc71', '#e74c3c']\n",
    "  axes[1].pie(class_counts.values, labels=class_counts.index, autopct=\"%1.1f%%\",\n",
    "  colors = colors, startangle=90)\n",
    "  axes[1].set_title('Class Proportion', fontsize = 14, fontweight = 'bold')\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.savefig('class_distribution.png', dpi = 300, bbox_inches = 'tight')\n",
    "  print(\"\\n Saved visualization: class_distribution.png\")\n",
    "  plt.close()\n",
    "  \n",
    "  return class_counts\n",
    "\n",
    "def generate_proxy_label() -> str:\n",
    "    \"\"\"\n",
    "    Calculates the simple, normalized YOLO label string for an 80x80 image\n",
    "    containing a 10x10 proxy bounding box at the center.\n",
    "\n",
    "    YOLO format: [class_id x_center_norm y_center_norm w_norm h_norm]\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Calculate normalised center point (always the center of the image)\n",
    "    x_center_norm = (IMAGE_SIZE / 2) / IMAGE_SIZE # 40/80 = 0.5\n",
    "    y_center_norm = (IMAGE_SIZE / 2) / IMAGE_SIZE # 40/80 = 0.5\n",
    "\n",
    "    # 2. Calculate normalised width and height\n",
    "    w_norm = PROXY_BOX_SIZE / IMAGE_SIZE # 10/80 = 0.125\n",
    "    h_norm = PROXY_BOX_SIZE / IMAGE_SIZE # 10/80 = 0.125\n",
    "\n",
    "    # 3. Format the final YOLO string\n",
    "    # We use the fixed SHIP_CLASS_ID (1)\n",
    "    label_string = f\"{SHIP_CLASS_ID} {x_center_norm:.3f} {y_center_norm:.3f} {w_norm:.3f} {h_norm:.3f}\"\n",
    "    return label_string\n",
    "    \n",
    "    \n",
    "\n",
    "def analyze_spatial_distribution(df):\n",
    "  \"\"\"\n",
    "  Analyze the geographic distribution of images\n",
    "  \"\"\"\n",
    "  \n",
    "  print(\"\\n\"+\"=\"*80)\n",
    "  print(\"2. SPATIAL DISTRIBUTION ANALYSIS\")\n",
    "  print(\"=\"*80)\n",
    "  \n",
    "  print(f\"\\nGeographic Coverage:\")\n",
    "  print(f\"  Longitude range: {df['longitude'].min():.4f} to {df['longitude'].max():.4f}\")\n",
    "  print(f\"  Latitude range: {df['latitude'].min():.4f} to {df['latitude'].max():.4f}\")\n",
    "  \n",
    "  # Calculate center point\n",
    "  center_lon = df['longitude'].mean()\n",
    "  center_lat = df['latitude'].mean()\n",
    "  print(f\"  Center point: ({center_lon:.4f}, {center_lat:.4f})\")\n",
    "  \n",
    "  # Visualization\n",
    "  fig, axes = plt.subplots(1,2, figsize = (16,6))\n",
    "  \n",
    "  # Scatter plot with ship/no-ship distinction\n",
    "  for idx, (label,color) in enumerate([('ship', '#e74c3c'), ('no-ship', '#2ecc71')]):\n",
    "    subset = df[df['label_name'] == label]\n",
    "    axes[0].scatter(subset['longitude'], subset['latitude'],\n",
    "    c=color, label = label, alpha = 0.6, s = 50, edgecolors = 'black', linewidth = 0.5)\n",
    "    \n",
    "  axes[0].set_title('Geographic Distribution of Images', fontsize = 14, fontweight = 'bold')\n",
    "  axes[0].set_xlabel('Longitude', fontsize = 12)\n",
    "  axes[0].set_ylabel('Latitude', fontsize = 12)\n",
    "  axes[0].legend(loc = 'best')\n",
    "  axes[0].grid(True, alpha = 0.3)\n",
    "  \n",
    "  # Density heatmap\n",
    "  axes[1].hexbin(df['longitude'], df['latitude'], gridsize = 30, cmap = 'YlOrRd', mincnt = 1)\n",
    "  axes[1].set_title('Spatial Density Heatmap', fontsize = 14, fontweight = 'bold')\n",
    "  axes[1].set_xlabel('Longitude', fontsize = 12)\n",
    "  axes[1].set_ylabel('Latitude', fontsize = 12)\n",
    "  plt.colorbar(axes[1].collections[0], ax = axes[1], label='Number of Images')\n",
    "  \n",
    "  plt.tight_layout()\n",
    "  plt.savefig('spatial_distribution.png', dpi = 300, bbox_inches = 'tight')\n",
    "  print(\"\\n Saved visualization: spatial_distribution.png\")\n",
    "  \n",
    "  plt.close()\n",
    "\n",
    "def analyze_spatial_distribution_map(df):\n",
    "    \"\"\"Analyze gepgraphic distribution using OpenStreetMap interactive map.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"2B. SPATIAL DISTRIBUTION ON OPENSTREETMAP\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    # Calculate center plot for map\n",
    "    center_lat = df['latitude'].mean()\n",
    "    center_lon = df['longitude'].mean()\n",
    "\n",
    "    print(f\"\\nCreative interactive map centered at ({center_lat:.4f}, {center_lon:.4f})\")\n",
    "\n",
    "    # Create base map\n",
    "    m = folium.Map(\n",
    "        location = [center_lat, center_lon],\n",
    "        zoom_start = 11,\n",
    "        tiles ='OpenStreetMap'\n",
    "    )\n",
    "\n",
    "    # Add additional tile layers\n",
    "    # Add additional tile layers with proper attributions\n",
    "    folium.TileLayer(\n",
    "        tiles='https://tiles.stadiamaps.com/tiles/stamen_terrain/{z}/{x}/{y}.png',\n",
    "        attr='Map tiles by Stadia Maps, under CC BY 3.0. Data by OpenStreetMap, under ODbL',\n",
    "        name='Terrain'\n",
    "    ).add_to(m)\n",
    "    \n",
    "    folium.TileLayer(\n",
    "        tiles='https://tiles.stadiamaps.com/tiles/stamen_toner/{z}/{x}/{y}.png',\n",
    "        attr='Map tiles by Stadia Maps, under CC BY 3.0. Data by OpenStreetMap, under ODbL',\n",
    "        name='Toner'\n",
    "    ).add_to(m)\n",
    "    \n",
    "    folium.TileLayer(\n",
    "        tiles='CartoDB positron',\n",
    "        name='CartoDB Light'\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Create separate feature groups for ships and no-ships\n",
    "    ship_group = folium.FeatureGroup(name = 'Ships', show = True)\n",
    "    no_ship_group = folium.FeatureGroup(name = 'No-Ships', show = True)\n",
    "\n",
    "    # Add markers for each image location\n",
    "    ship_count = 0\n",
    "    no_ship_count = 0\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        lat = row['latitude']\n",
    "        lon = row['longitude']\n",
    "        label = row['label_name']\n",
    "        scene_id = row['scene_id']\n",
    "\n",
    "        # Create popup content\n",
    "        popup_html = f\"\"\"\n",
    "        <div style=\"font-family: Arial; font-size: 12px;\">\n",
    "            <b>Label:</b> {label}<br>\n",
    "            <b>Scene ID:</b> {scene_id} <br>\n",
    "            <b> Coordinates: </b><br>\n",
    "            Lat: {lat:.6f}<br>\n",
    "            Lon: {lon:.6f}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "\n",
    "        if label == 'ship':\n",
    "            folium.CircleMarker(\n",
    "                location = [lat, lon],\n",
    "                radius = 5,\n",
    "                popup = folium.Popup(popup_html, max_width = 250),\n",
    "                color = '#e74c3c',\n",
    "                fill = True,\n",
    "                fillColor = '#e74c3c',\n",
    "                fillOpacity = 0.7,\n",
    "                weight = 2,\n",
    "            ).add_to(ship_group)\n",
    "            ship_count += 1\n",
    "        else:\n",
    "            folium.CircleMarker(\n",
    "                location = [lat, lon],\n",
    "                radius = 5,\n",
    "                popup = folium.Popup(popup_html, max_width = 250),\n",
    "                color = '#2ecc71',\n",
    "                fill = True,\n",
    "                fillColor = '#2ecc71',\n",
    "                fillOpacity = 0.7,\n",
    "                weight = 2\n",
    "            ).add_to(no_ship_group)\n",
    "            no_ship_count += 1\n",
    "\n",
    "    # Add feature groups to map\n",
    "    ship_group.add_to(m)\n",
    "    no_ship_group.add_to(m)\n",
    "\n",
    "    # Add heatmap layer for overall density\n",
    "    heat_data = [[row['latitude'], row['longitude']] for _, row in df.iterrows()]\n",
    "    plugins.HeatMap(\n",
    "        heat_data,\n",
    "        name = 'Density Heatmap',\n",
    "        min_opacity = 0.3,\n",
    "        max_zoom = 13,\n",
    "        radius = 15,\n",
    "        blur = 20,\n",
    "        show = False\n",
    "    ).add_to(m)\n",
    "\n",
    "    # Add a marker cluster layer (optional, for dense data)\n",
    "    marker_cluster = plugins.MarkerCluster(name = 'Clustered View', show = False)\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        lat = row['latitude']\n",
    "        long = row['longitude']\n",
    "        label = row['label_name']\n",
    "        color = 'red' if label == 'ship' else 'green'\n",
    "\n",
    "        folium.Marker(\n",
    "            location = [lat, lon],\n",
    "            popup = f\"{label} <br> { row['scene_id']}\",\n",
    "            icon = folium.Icon(color = color, icon = 'ship' if label == 'ship' else 'water', prefix = 'fa')\n",
    "        ).add_to(marker_cluster)\n",
    "\n",
    "    marker_cluster.add_to(m)\n",
    "\n",
    "    # Add layer control\n",
    "    folium.LayerControl(collapse = False).add_to(m)\n",
    "\n",
    "    # Add legend\n",
    "    legend_html = \"\"\"\n",
    "    <div style=\"positron: fixed;\n",
    "                bottom: 50px; right: 50px; width: 180px; height: 120px;\n",
    "                background-color: white; border:2px solid grey; z-index:9999;\n",
    "                font-size:14px; padding: 10px>\n",
    "            <p style = \"margin: 0; font-weight: bold;\">Legend</p>\n",
    "            <p style = \"margin: 5px 0;\">\n",
    "                <spam style =\"color: #e74c3c; font-size: 20px;\">●</span> Ships ({})\n",
    "            </p>\n",
    "            <p style = \"margin: 5px 0;\">\n",
    "                <spam style = \"color: #2ecc71; font-size: 20px;\">●</span> No Ships ({})\n",
    "            </p>\n",
    "            <p style = \"margin: 5px 0; font-size: 11px; color = #666;\">\n",
    "                Click markers for details\n",
    "            </p>\n",
    "    </div>\n",
    "    \"\"\".format(ship_count, no_ship_count)\n",
    "\n",
    "    m.get_root().html.add_child(folium.Element(legend_html))\n",
    "\n",
    "    # Save map\n",
    "    map_file = 'spatial_distribution_map.html'\n",
    "    m.save(map_file)\n",
    "\n",
    "    print(f\"  Ship locations: {ship_count}\")\n",
    "    print(f\"  No-ship locations: {no_ship_count}\")\n",
    "    print(f\"\\n Saved interactive map: {map_file}\")\n",
    "    print(\"  Open the HTML file in a web browser to explore the map\")\n",
    "    print(\" Features: Toggle layers, zoom, pan, click marker for details\")\n",
    "\n",
    "def upscale_positive_ships(input_dir, output_dir, df):\n",
    "    \"\"\"\n",
    "    Filters the DataFrame for 'ship' labels, loads the corresponfing 80x80 images,\n",
    "    resizes them to 640x640, and saves to the output path\n",
    "\n",
    "    Args:\n",
    "        input_dir: Path where the original 80x80 images are stores\n",
    "        output_dir: Path where the upscaled 640x640 images will be saved.\n",
    "        df: DataFrame containing image metadata, including the 'label' column.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\n---- Starting image Upscaling Process ----\")\n",
    "\n",
    "    # 1. Ensure output directory exists\n",
    "    os.makedirs(output_dir, exist_ok = True)\n",
    "\n",
    "    # 2. Filter for positive samples (images containing ships)\n",
    "    positive_df = df[df['label'] == 1].reset_index(drop = True)\n",
    "    num_to_upscale = len(positive_df)\n",
    "\n",
    "    print(f\"Found {num_to_upscale} positive samples ('ship' label) to upscale.\")\n",
    "\n",
    "    if num_to_upscale == 0:\n",
    "        print(\"No positive samples found. Skipping upscaling.\")\n",
    "        return\n",
    "\n",
    "    # 3. Iterate, Upscale, and Save\n",
    "    start_time = time.time()\n",
    "\n",
    "    for index, row in positive_df.iterrows():\n",
    "        filename = row['filename']\n",
    "        input_path = os.path.join(input_dir, filename)\n",
    "        output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "        try:\n",
    "            # Load the 80x80 image using PIL\n",
    "            img = Image.open(input_path)\n",
    "\n",
    "            # Upscale the image to 640x640 (YOLO input size)\n",
    "            # Image Resampling.BILINEAR or BICUBIC\n",
    "            upscaled_img = img.resize((OUTPUT_SIZE, OUTPUT_SIZE), Image.Resampling.BICUBIC)\n",
    "\n",
    "            # Savet the upscale image\n",
    "            upscaled_img.save(output_path)\n",
    "\n",
    "            if index % 10 == 0:\n",
    "                print(f\"[{index}/{num_to_upscale}] Upscaled and saved: {filename}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR processing {filename}: {e}. Skipping.\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f\"\\nSuccessfully upscaled {num_to_upscale} images to {OUTPUT_SIZE}x{OUTPUT_SIZE}px.\")\n",
    "    print(f\"Total processing time: {end_time - sart_time:.2f} seconds.\")\n",
    "          \n",
    "            \n",
    "\n",
    "\n",
    "def analyze_scene_distribution(df):\n",
    "    \"\"\"Analyze distribution across differente satellite scenes.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"3. SCENE DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    scene_counts = df['scene_id'].value_counts()\n",
    "    print(f\"\\nTotal unique scenes: {len(scene_counts)}\")\n",
    "    print(f\"Images per scene - Mean: {scene_counts.mean():.1f}, Median: {scene_counts.median():.1f}\")\n",
    "    print(f\"Images per scene - Min: {scene_counts.min()}, Max: {scene_counts.max()}\")\n",
    "\n",
    "    print(f\"\\nTop 10 scenes by image count:\")\n",
    "    for i, (scene_id, count) in enumerate(scene_counts.head(10).items(), 1):\n",
    "        print(f\" {i:2d}, {scene_id}:  {count} images\")\n",
    "\n",
    "    # Analize class distribution per scene\n",
    "    \n",
    "    scene_class_dist = df.groupby(['scene_id', 'label_name']).size().unstack(fill_value = 0)\n",
    "    print(f\"\\nScenes with only ships: {(scene_class_dist['ship'] > 0) & (scene_class_dist['no-ship'] == 0).sum()}\")\n",
    "    print(f\"Scenes with only no-ships: {(scene_class_dist['no-ship'] > 0) & (scene_class_dist['ship'] == 0).sum()}\")\n",
    "    print(f\"Scenes with both classes: {((scene_class_dist['ship'] > 0) & (scene_class_dist['no-ship'] > 0)).sum()}\")\n",
    "\n",
    "\n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize = (16 , 6))\n",
    "\n",
    "    # Distribution of images per scene\n",
    "    axes[0].hist(scene_counts.values, bins = 30, color = '#3498db', edgecolor = 'black', alpha = 0.7)\n",
    "    axes[0].set_title('Distribution of Images per Scene', fontsize = 14, fontweight = 'bold')\n",
    "    axes[0].set_xlabel('Number of Images', fontsize = 12)\n",
    "    axes[0].set_ylabel('Number of Scenes', fontsize = 12)\n",
    "    axes[0].axvline(scene_counts.mean(), color = 'red', linestyle = '--', linewidth = 2, label = f'Mean: {scene_counts.mean():.1f}')\n",
    "    axes[0].axvline(scene_counts.median(), color = 'green', linestyle = '--', linewidth = 1, label = f'Median: {scene_counts.median():.1f}')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(axis = 'y', alpha = 0.3)\n",
    "\n",
    "    # Top scenes bar plot\n",
    "    top_scenes = scene_counts.head(15)\n",
    "    axes[1].barh(range(len(top_scenes)), top_scenes.values, color = '#9b59b6')\n",
    "    axes[1].set_yticks(range(len(top_scenes)))\n",
    "    axes[1].set_yticklabels([scene_id[:20] + '...' if len(scene_id) > 20 else scene_id for scene_id in top_scenes.index], fontsize = 9)\n",
    "    axes[1].set_xlabel('Number of Images', fontsize = 12)\n",
    "    axes[1].set_title('Top 15 scenes by Image Count', fontsize = 14, fontweight = 'bold')\n",
    "    axes[1].invert_yaxis()\n",
    "    axes[1].grid(axis = 'x', alpha = 0.3)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('scene_distribution.png', dpi = 300, bbox_inches = 'tight')\n",
    "    print(\"\\n Saved visualization: scene_distribution.png\")\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "  \n",
    "def analyze_image_properties(dataset_path, df, sample_size = 50):\n",
    "  \"\"\"\n",
    "  Analyze image properties like dimension, color distribution, etc.\n",
    "  \"\"\"\n",
    "  \n",
    "  print(\"\\n\"+\"=\"*80)\n",
    "  print(\"4. IMAGE PROPERTIES ANALYSIS\")\n",
    "  print(\"=\"*80)\n",
    "  \n",
    "  # Sample images for detailed analysis\n",
    "  sample_df = df.sample(min(sample_size, len(df)),random_state = 42)\n",
    "  \n",
    "  image_stats = []\n",
    "  for _, row in sample_df.iterrows():\n",
    "    img_path = os.path.join(dataset_path, row['filename'])\n",
    "    try:\n",
    "      img = Image.open(img_path)\n",
    "      img_array = np.array(img)\n",
    "      \n",
    "      stats = {\n",
    "        'filename': row['filename'],\n",
    "        'label': row['label_name'],\n",
    "        'width': img.width,\n",
    "        'height': img.height,\n",
    "        'channels': img_array.shape[2] if len(img_array.shape) == 3 else 1,\n",
    "        'mean_intensity': img_array.mean(),\n",
    "        'std_intensity': img_array.std(),\n",
    "        'min_intensity': img_array.min(),\n",
    "        'max_intensity': img_array.max()\n",
    "      }\n",
    "      \n",
    "      image_stats.append(stats)\n",
    "    except Exception as e:\n",
    "      print(f\"Error processing {row['filename']}: {e}\")\n",
    "  stats_df = pd.DataFrame(image_stats)\n",
    "  \n",
    "  print(f\"\\nImage properties (based on {len(stats_df)} sample images):\")\n",
    "  print(f\"  Image dimensions: {stats_df['width'].iloc[0]}x{stats_df['height'].iloc[0]} pixels\")\n",
    "  print(f\"  Color chanels: {stats_df['channels'].iloc[0]} (RGB)\")\n",
    "  print(f\"  Pixel coverage: {stats_df['width'].iloc[0] * 3}m x {stats_df['height'].iloc[0] * 3}m = {(stats_df['width'].iloc[0] * 3 * stats_df['height'].iloc[0] * 3) / 1000000:.2f} km²\")\n",
    "  \n",
    "  print(f\"\\nIntensive Statistics:\")\n",
    "  print(f\"  Mean intensity - Ship: {stats_df[stats_df['label'] == 'ship']['mean_intensity'].mean():.2f}\")\n",
    "  print(f\"  Mean intensity - No-ship: {stats_df[stats_df['label'] == 'no-ship']['mean_intensity'].mean():.2f}\")\n",
    "  print(f\"  Std intensity - Ship: {stats_df[stats_df['label'] == 'ship']['std_intensity'].mean():.2f}\")\n",
    "  print(f\"  Std intensity - No-ship: {stats_df[stats_df['label'] == 'no-ship']['std_intensity'].mean():.2f}\")\n",
    "  \n",
    "  # Visualization\n",
    "  fig, axes = plt.subplots(2,2, figsize = (14, 10))\n",
    "  \n",
    "  # Mean intensity distribution\n",
    "  stats_df[stats_df['label'] == 'ship']['mean_intensity'].hist(ax=axes[0,0], bins = 20,\n",
    "  color = '#e74c3c', alpha = 0.7, label = 'Ship')\n",
    "  stats_df[stats_df['label'] == 'no-ship']['mean_intensity'].hist(ax=axes[0,0], bins = 20, color = '#e74c3c', alpha = 0.7, label = 'No-ship')\n",
    "  axes[0,0].set_title('Mean Pixel Intensity Distribution', fontsize = 12, fontweight = 'bold')\n",
    "  axes[0,0].set_xlabel('Mean Intensity', fontsize = 10)\n",
    "  axes[0,0].set_ylabel('Frequency', fontsize = 10)\n",
    "  axes[0,0].legend()\n",
    "  axes[0,0].grid(axis = 'y', alpha = 0.3)\n",
    "  \n",
    "  # Std intensity distribution\n",
    "  stats_df[stats_df['label'] == 'ship']['std_intensity'].hist(ax = axes[0,1], bins = 20, color = '#e74c3c', alpha = 0.7, label = 'Ship')\n",
    "  stats_df[stats_df['label'] == 'no-ship']['std_intensity'].hist(ax = axes[0,1], bins = 20, color = '#2ecc71', alpha = 0.7, label = 'No-ship')\n",
    "  axes[0,1].set_title('Std Pixel Itensity Distribution', fontsize = 12, fontweight = 'bold')\n",
    "  axes[0,1].set_xlabel('Std Intensity', fontsize = 10)\n",
    "  axes[0,1].set_ylabel('Frequency', fontsize = 10)\n",
    "  axes[0,1].legend()\n",
    "  axes[0,1].grid(axis = 'y', alpha = 0.3)\n",
    "  \n",
    "  # Sample images - Ships\n",
    "  ship_samples = df[df['label_name'] == 'ship'].sample(min(4, len(df[df['label_name'] == 'ship'])), random_state = 42)\n",
    "  for idx, (_, row) in enumerate(ship_samples.iterrows()):\n",
    "    if idx >= 2:\n",
    "      break\n",
    "    img_path = os.path.join(dataset_path, row['filename'])\n",
    "    try:\n",
    "      img = Image.open(img_path)\n",
    "      axes[1, idx].imshow(img)\n",
    "      axes[1, idx].set_title(f'Ship Example {idx+1}', fontsize = 10, fontweight = 'bold')\n",
    "      axes[1, idx].axis('off')\n",
    "    except:\n",
    "      pass\n",
    "    \n",
    "  plt.tight_layout()\n",
    "  plt.savefig('image_properties.png', dpi = 300, bbox_inches = 'tight')\n",
    "  print(\"\\n Saved visualizations: image_properties.png\")\n",
    "  plt.close()\n",
    "  \n",
    "  return stats_df\n",
    "\n",
    "def generate_summary_report(df, class_counts):\n",
    "  \"\"\"Generate a comprehensive summary report.\"\"\"\n",
    "  print(\"\\n\" + \"=\"*80)\n",
    "  print(\"5. DATASET SUMMARY REPORT\")\n",
    "  print(\"=\"*80)\n",
    "  \n",
    "  summary = f\"\"\"\n",
    "  Data Characteristics:\n",
    "    ------------------\n",
    "    Total Images: {len(df)}\n",
    "    Imate Resulution: 80x80 pixels (240m x 240m ground coverage)\n",
    "    Pixel Resolution: 3 meters per nivel \n",
    "    Color Channels: 3 (RGB)\n",
    "    \n",
    "    Class Distribution:\n",
    "      ----------------\n",
    "      Ship Images: {class_counts.get('ship',0)} ({(class_counts.get('ship', 0)/len(df)*100):.1f}%)\n",
    "      No-Ship Images: {class_counts.get('no-ship', 0)} ({(class_counts.get('no-ship', 0)/ len(df)*100):,.1f}%)\n",
    "    \n",
    "    Geopraphic Coverage:\n",
    "      -----------------\n",
    "      Longitude Range: {df['longitude'].min():.4f}\" to {df['longitude'].max():.4f}\"\n",
    "      Latitude Range: {df['latitude'].min():.4f}\" to {df['latitude'].max():.4f}\"\n",
    "      Center Point: ({df['Longitude'].mean():4f}\",{df['latitude'].mean():.4f}\")\n",
    "      \n",
    "    Scene Information:\n",
    "      ----------------\n",
    "      Unique Scenes: {df['scene_id'].unique()}\n",
    "      Average Images per Scene: {df.groupby('scene_id').size().mean():.1f)}\n",
    "      \n",
    "      Key Findings:\n",
    "        -----------\n",
    "        1. The dataset is relatively balanced between ship and no-ship classes\n",
    "        2. Images are concentrated around the California coastline.\n",
    "        3. Multiple scenes provide temporal diversity\n",
    "        4. Consistent 80x80 pixel format suitable for CNN-based approaches\n",
    "        5. 3-meter resolution is appropriate for detecting large vessels\n",
    "        \n",
    "        Recomendations:\n",
    "          ------------\n",
    "          1. Dataset is suitable for supervised learning approaches\n",
    "          2. Consider data augmentation to improve model robustness\n",
    "          3. Implement train/validation/test split stratified by scene_id\n",
    "          4. Use transfer learning with pre-trained models (e.g ResNet, EfficientNet)\n",
    "          5. Consider essemble methods for production deployment\n",
    "\"\"\"\n",
    "\n",
    "  print(summary)\n",
    "  \n",
    "  # Save report to file\n",
    "  with open('dataset_summary_report.txt', 'w') as f:\n",
    "    f.write(\"SHIP DETECTION DATASET - EXPLORATORY DATA ANALYSIS\\n\")\n",
    "    f.write(\"California Environmental Agency\\n\")\n",
    "    f.write(\"=\"*80 + \"\\n\")\n",
    "    f.write(summary)\n",
    "    \n",
    "  print(\"\\n Saved report: dataset_summary_report.txt\")\n",
    "\n",
    "\n",
    "  \n",
    "      \n",
    "  \n",
    "  \n",
    "  \n",
    "  \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f378d9bd-1e08-4350-a832-21070073e492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "SHIP DETECTION DATASET - EXPLORATORY DATA ANALYSIS\n",
      "========================================================================================\n",
      "\n",
      " Successfully loaded 4000 inages from a total of 4000\n",
      "\n",
      "================================================================================\n",
      "1. CLASS DISTRIBUTION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Class Distribution:\n",
      "  no-ship   :  3000  images  (75.00%)\n",
      "  ship      :  1000  images  (25.00%)\n",
      "\n",
      "Class Imbalance Ratio: 3.000000:1\n",
      "Warning: Significant class imbalance detected\n",
      "Recommendation: Considerar class weighting or data augmentation\n",
      "\n",
      " Saved visualization: class_distribution.png\n",
      "\n",
      "================================================================================\n",
      "2. SPATIAL DISTRIBUTION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Geographic Coverage:\n",
      "  Longitude range: -122.6763 to -117.9021\n",
      "  Latitude range: 33.6290 to 37.9035\n",
      "  Center point: (-121.7676, 37.2023)\n",
      "\n",
      " Saved visualization: spatial_distribution.png\n",
      "\n",
      "================================================================================\n",
      "2B. SPATIAL DISTRIBUTION ON OPENSTREETMAP\n",
      "================================================================================\n",
      "\n",
      "Creative interactive map centered at (37.2023, -121.7676)\n",
      "  Ship locations: 1000\n",
      "  No-ship locations: 3000\n",
      "\n",
      " Saved interactive map: spatial_distribution_map.html\n",
      "  Open the HTML file in a web browser to explore the map\n",
      " Features: Toggle layers, zoom, pan, click marker for details\n",
      "\n",
      "================================================================================\n",
      "3. SCENE DISTRIBUTION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Total unique scenes: 434\n",
      "Images per scene - Mean: 9.2, Median: 7.0\n",
      "Images per scene - Min: 1, Max: 39\n",
      "\n",
      "Top 10 scenes by image count:\n",
      "  1, 20180712_180429_101b:  39 images\n",
      "  2, 20180712_180755_0f2d:  38 images\n",
      "  3, 20161218_180845_0e26:  37 images\n",
      "  4, 20180708_180453_0f28:  36 images\n",
      "  5, 20170515_180653_1007:  34 images\n",
      "  6, 20170622_180819_1034:  33 images\n",
      "  7, 20180708_180908_0f47:  32 images\n",
      "  8, 20180711_180503_1027:  30 images\n",
      "  9, 20170129_181027_0e1f:  30 images\n",
      " 10, 20180712_211331_0f06:  30 images\n",
      "\n",
      "Scenes with only ships: scene_id\n",
      "20150718_184300_090b      False\n",
      "20150720_184302_0906      False\n",
      "20150830_000650_0b07      False\n",
      "20150830_000652_1_0b07     True\n",
      "20160622_170157_0c64      False\n",
      "                          ...  \n",
      "20180713_180403_1035       True\n",
      "20180714_180352_100e       True\n",
      "20180714_180427_1029       True\n",
      "20180714_182155_1051       True\n",
      "20180714_182329_101d      False\n",
      "Name: ship, Length: 434, dtype: bool\n",
      "Scenes with only no-ships: scene_id\n",
      "20150718_184300_090b      False\n",
      "20150720_184302_0906      False\n",
      "20150830_000650_0b07      False\n",
      "20150830_000652_1_0b07    False\n",
      "20160622_170157_0c64      False\n",
      "                          ...  \n",
      "20180713_180403_1035      False\n",
      "20180714_180352_100e      False\n",
      "20180714_180427_1029      False\n",
      "20180714_182155_1051      False\n",
      "20180714_182329_101d      False\n",
      "Name: no-ship, Length: 434, dtype: bool\n",
      "Scenes with both classes: 213\n",
      "\n",
      " Saved visualization: scene_distribution.png\n",
      "\n",
      "================================================================================\n",
      "4. IMAGE PROPERTIES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Image properties (based on 50 sample images):\n",
      "  Image dimensions: 80x80 pixels\n",
      "  Color chanels: 3 (RGB)\n",
      "  Pixel coverage: 240m x 240m = 0.06 km²\n",
      "\n",
      "Intensive Statistics:\n",
      "  Mean intensity - Ship: 84.81\n",
      "  Mean intensity - No-ship: 108.23\n",
      "  Std intensity - Ship: 29.66\n",
      "  Std intensity - No-ship: 27.70\n",
      "\n",
      " Saved visualizations: image_properties.png\n",
      "\n",
      "---- Starting image Upscaling Process ----\n",
      "Found 1000 positive samples ('ship' label) to upscale.\n",
      "[0/1000] Upscaled and saved: 1__20180707_182444_0f17__-122.34311776171931_37.71924997468138.png\n",
      "[10/1000] Upscaled and saved: 1__20170830_181003_0f4e__-122.33468859786528_37.75968074611797.png\n",
      "[20/1000] Upscaled and saved: 1__20170622_180819_1034__-122.3476851793261_37.73795963351161.png\n",
      "[30/1000] Upscaled and saved: 1__20170613_180813_1017__-122.32797567677703_37.737470359752315.png\n",
      "[40/1000] Upscaled and saved: 1__20180708_180453_0f28__-118.16017519031635_33.735042630685086.png\n",
      "[50/1000] Upscaled and saved: 1__20180305_184041_1054__-122.34522826530379_37.75790109894697.png\n",
      "[60/1000] Upscaled and saved: 1__20170909_181400_0f28__-122.35160715732775_37.74893224727843.png\n",
      "[70/1000] Upscaled and saved: 1__20171025_175648_0e26__-118.22893579949042_33.71995675330757.png\n",
      "[80/1000] Upscaled and saved: 1__20170619_181346_0e30__-122.32751817128485_37.70899515508011.png\n",
      "[90/1000] Upscaled and saved: 1__20170609_180756_103a__-122.34908354683306_37.74935096766827.png\n",
      "[100/1000] Upscaled and saved: 1__20170730_191230_0f21__-122.3348862206096_37.72999258493115.png\n",
      "[110/1000] Upscaled and saved: 1__20170910_181215_1010__-122.35000422761132_37.78034313695685.png\n",
      "[120/1000] Upscaled and saved: 1__20170716_180816_103a__-122.34916689604478_37.739833546904364.png\n",
      "[130/1000] Upscaled and saved: 1__20170504_180549_1025__-122.3448115019479_37.731778695498306.png\n",
      "[140/1000] Upscaled and saved: 1__20170619_181346_0e30__-122.33663561156446_37.7590427773507.png\n",
      "[150/1000] Upscaled and saved: 1__20170702_180943_103c__-122.34838072324455_37.74018071626868.png\n",
      "[160/1000] Upscaled and saved: 1__20170328_181231_0e0f__-122.35296881171361_37.75680819640679.png\n",
      "[170/1000] Upscaled and saved: 1__20171118_181532_1030__-122.34627580657862_37.72786609802154.png\n",
      "[180/1000] Upscaled and saved: 1__20180708_180908_0f47__-118.14802500079567_33.72969092405789.png\n",
      "[190/1000] Upscaled and saved: 1__20170522_180635_0f42__-122.34140533621209_37.74733443586415.png\n",
      "[200/1000] Upscaled and saved: 1__20170730_181513_0e20__-122.33201924904884_37.74974219917557.png\n",
      "[210/1000] Upscaled and saved: 1__20170923_181241_0f42__-122.33247965400024_37.747770931971786.png\n",
      "[220/1000] Upscaled and saved: 1__20170730_181043_103d__-122.33195163144038_37.749687737152065.png\n",
      "[230/1000] Upscaled and saved: 1__20180705_213444_0f02__-122.31908883301435_37.70775703482464.png\n",
      "[240/1000] Upscaled and saved: 1__20170731_181111_100c__-122.33710430982418_37.72941021040814.png\n",
      "[250/1000] Upscaled and saved: 1__20180707_182444_0f17__-122.32060425459107_37.709523348129174.png\n",
      "[260/1000] Upscaled and saved: 1__20170211_181116_0e16__-122.32842853639183_37.73633728423106.png\n",
      "[270/1000] Upscaled and saved: 1__20170609_180757_103a__-122.32202757086094_37.71767044207262.png\n",
      "[280/1000] Upscaled and saved: 1__20150830_000652_1_0b07__-122.32370681389538_37.72016772243502.png\n",
      "[290/1000] Upscaled and saved: 1__20170504_180549_1025__-122.33593285673965_37.730971906981296.png\n",
      "[300/1000] Upscaled and saved: 1__20170609_180751_101b__-122.32675050227115_37.73740928946283.png\n",
      "[310/1000] Upscaled and saved: 1__20170515_180654_1007__-122.34103785170488_37.719643960374654.png\n",
      "[320/1000] Upscaled and saved: 1__20170619_180825_1032__-122.33919364707803_37.739480622890724.png\n",
      "[330/1000] Upscaled and saved: 1__20170703_180945_1009__-122.33876092330141_37.76897815629974.png\n",
      "[340/1000] Upscaled and saved: 1__20170505_181258_0e2f__-122.338448217423_37.73907084984848.png\n",
      "[350/1000] Upscaled and saved: 1__20180210_181908_1006__-122.34975403850396_37.77001274518038.png\n",
      "[360/1000] Upscaled and saved: 1__20170707_181135_100b__-122.33169404987292_37.74803687398289.png\n",
      "[370/1000] Upscaled and saved: 1__20180205_181922_1031__-122.36027037593409_37.77107076127549.png\n",
      "[380/1000] Upscaled and saved: 1__20170703_180945_1009__-122.32507595039102_37.71933734373484.png\n",
      "[390/1000] Upscaled and saved: 1__20160820_233143_0c53__-122.36026478492359_37.771719674794056.png\n",
      "[400/1000] Upscaled and saved: 1__20170721_180825_100b__-122.32613080820607_37.73816285249999.png\n",
      "[410/1000] Upscaled and saved: 1__20180708_180909_0f47__-118.22948084941048_33.72866321979766.png\n",
      "[420/1000] Upscaled and saved: 1__20170818_180847_1035__-122.32856032371593_37.73682474496772.png\n",
      "[430/1000] Upscaled and saved: 1__20180708_182359_1032__-122.3480759546276_37.73998975485291.png\n",
      "[440/1000] Upscaled and saved: 1__20180705_182236_0f4d__-122.33953638448827_37.769874802316046.png\n",
      "[450/1000] Upscaled and saved: 1__20171118_185722_0f2d__-122.34006393759125_37.71815133796416.png\n",
      "[460/1000] Upscaled and saved: 1__20170717_180818_1010__-122.33052997944398_37.74873329184904.png\n",
      "[470/1000] Upscaled and saved: 1__20180708_180453_0f28__-118.1602075693253_33.73504232642754.png\n",
      "[480/1000] Upscaled and saved: 1__20171022_175534_100e__-118.2215443724113_33.73071704665499.png\n",
      "[490/1000] Upscaled and saved: 1__20171127_181538_101e__-122.35285080613363_37.7859829726792.png\n",
      "[500/1000] Upscaled and saved: 1__20171022_175534_100e__-118.25263689798176_33.71111496385489.png\n",
      "[510/1000] Upscaled and saved: 1__20170615_180728_1003__-122.34225811089621_37.75101655694937.png\n",
      "[520/1000] Upscaled and saved: 1__20170722_181118_101f__-122.4678646008189_37.82506252336944.png\n",
      "[530/1000] Upscaled and saved: 1__20180712_180428_101b__-118.1593929991596_33.73467119714559.png\n",
      "[540/1000] Upscaled and saved: 1__20170619_180826_1032__-122.34445250403449_37.70297957681386.png\n",
      "[550/1000] Upscaled and saved: 1__20180711_180503_1027__-118.22754369384589_33.72906127099897.png\n",
      "[560/1000] Upscaled and saved: 1__20170721_180937_0f31__-122.34546403473743_37.758199841678305.png\n",
      "[570/1000] Upscaled and saved: 1__20170106_180852_0e30__-122.33010562564398_37.71268726512258.png\n",
      "[580/1000] Upscaled and saved: 1__20170613_180813_1017__-122.3346378281546_37.72731427394284.png\n",
      "[590/1000] Upscaled and saved: 1__20180710_182342_1011__-122.33031271979189_37.71614950348854.png\n",
      "[600/1000] Upscaled and saved: 1__20180712_180755_0f2d__-118.16439827013708_33.72883415776477.png\n",
      "[610/1000] Upscaled and saved: 1__20170609_180751_101b__-122.32199328731252_37.71769728443183.png\n",
      "[620/1000] Upscaled and saved: 1__20180710_182342_1011__-122.33426530656922_37.727095854810166.png\n",
      "[630/1000] Upscaled and saved: 1__20170618_180801_0f34__-122.33198495409655_37.7497690441889.png\n",
      "[640/1000] Upscaled and saved: 1__20170901_181520_0e14__-122.35035768163974_37.7672039845457.png\n",
      "[650/1000] Upscaled and saved: 1__20170827_181130_1014__-122.33912795640656_37.73920986014904.png\n",
      "[660/1000] Upscaled and saved: 1__20171129_181545_1022__-122.32926284720676_37.738207756054706.png\n",
      "[670/1000] Upscaled and saved: 1__20180714_182155_1051__-122.34193815177993_37.71791845851837.png\n",
      "[680/1000] Upscaled and saved: 1__20170822_181223_0f31__-122.32330764160088_37.72662787120537.png\n",
      "[690/1000] Upscaled and saved: 1__20170419_180519_1009__-122.33062239136795_37.74981539224976.png\n",
      "[700/1000] Upscaled and saved: 1__20180706_180314_1024__-118.13775769372789_33.6779466676366.png\n",
      "[710/1000] Upscaled and saved: 1__20170414_180529_0f28__-122.35735977825489_37.76889177756483.png\n",
      "[720/1000] Upscaled and saved: 1__20170815_180822_102d__-122.34406838557017_37.750404739560416.png\n",
      "[730/1000] Upscaled and saved: 1__20170615_181425_0e0d__-122.3304854528943_37.74989573259224.png\n",
      "[740/1000] Upscaled and saved: 1__20170919_181412_0f1b__-122.35520402175558_37.75825353423596.png\n",
      "[750/1000] Upscaled and saved: 1__20180706_180914_1051__-118.21561551008004_33.70063556051552.png\n",
      "[760/1000] Upscaled and saved: 1__20180705_213444_0f02__-122.33112497702128_37.7166678658198.png\n",
      "[770/1000] Upscaled and saved: 1__20170106_180851_0e30__-122.3360897908182_37.72864739533354.png\n",
      "[780/1000] Upscaled and saved: 1__20180713_180403_1035__-118.16429785193365_33.72859160251572.png\n",
      "[790/1000] Upscaled and saved: 1__20180712_211332_0f06__-118.20615276144385_33.706815861818534.png\n",
      "[800/1000] Upscaled and saved: 1__20180708_180453_0f28__-118.22543628460696_33.73798347719339.png\n",
      "[810/1000] Upscaled and saved: 1__20170515_180653_1007__-122.33952619157952_37.7403747883417.png\n",
      "[820/1000] Upscaled and saved: 1__20170919_181413_0f1b__-122.33481795170351_37.72620667112722.png\n",
      "[830/1000] Upscaled and saved: 1__20180714_180427_1029__-118.22589617269283_33.72250313487135.png\n",
      "[840/1000] Upscaled and saved: 1__20170613_180813_1017__-122.32641024925597_37.70731237736626.png\n",
      "[850/1000] Upscaled and saved: 1__20180712_180429_101b__-118.15136167018031_33.6958399694963.png\n",
      "[860/1000] Upscaled and saved: 1__20171119_181612_0f52__-122.34558216091033_37.75638885974003.png\n",
      "[870/1000] Upscaled and saved: 1__20170609_180756_103a__-122.34417038995429_37.758138571050885.png\n",
      "[880/1000] Upscaled and saved: 1__20171022_175534_100e__-118.16499076011308_33.727151109873056.png\n",
      "[890/1000] Upscaled and saved: 1__20170414_180529_0f28__-122.354012063916_37.758247006690844.png\n",
      "[900/1000] Upscaled and saved: 1__20171217_181637_1032__-122.34338830121405_37.75799901938855.png\n",
      "[910/1000] Upscaled and saved: 1__20180705_213444_0f02__-122.3287178577925_37.73823169303052.png\n",
      "[920/1000] Upscaled and saved: 1__20170830_181004_0f4e__-122.33472265432373_37.759680938376434.png\n",
      "[930/1000] Upscaled and saved: 1__20180712_180755_0f2d__-118.22757645503992_33.729088000848975.png\n",
      "[940/1000] Upscaled and saved: 1__20180713_180403_1035__-118.16956361406372_33.73484583123226.png\n",
      "[950/1000] Upscaled and saved: 1__20180706_180314_1024__-118.15211255098062_33.69631997662297.png\n",
      "[960/1000] Upscaled and saved: 1__20170501_180610_100e__-122.32991143835491_37.73802216894001.png\n",
      "[970/1000] Upscaled and saved: 1__20180712_180429_101b__-118.20723528527067_33.707833403507784.png\n",
      "[980/1000] Upscaled and saved: 1__20170522_180635_0f42__-122.34764717161039_37.75780635583718.png\n",
      "[990/1000] Upscaled and saved: 1__20180707_180451_102e__-118.14821854294323_33.72963501275399.png\n",
      "\n",
      "Successfully upscaled 1000 images to 640x640px.\n",
      "ERROR: There are files in the directory /home/jsancheg/git_environment/CalEnvAgency/data/processed. Elimine those files from the directory first.\n"
     ]
    }
   ],
   "source": [
    "df = load_dataset_metadata(INPUT_PATH)\n",
    "\n",
    "# Perform analyses\n",
    "class_counts = analyze_class_distribution(df)\n",
    "analyze_spatial_distribution(df)\n",
    "analyze_spatial_distribution_map(df)\n",
    "analyze_scene_distribution(df)\n",
    "stats_df = analyze_image_properties(INPUT_PATH, df)\n",
    "\n",
    "directory = Path(OUTPUT_PATH)\n",
    "\n",
    "if directory.exists() and directory.is_dir():\n",
    "    # Count files (not including subdirectories)\n",
    "    file_count = len([f for f in directory.iterdir() if f.is_file()])\n",
    "    if file_count == 0:\n",
    "        try:\n",
    "            upscale_positive_ships(INPUT_PATH, OUTPUT_PATH, df)\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: There are files in the directory {OUTPUT_PATH}. Elimine those files from the directory first.\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "709e7e64-e5fe-4e4c-966f-873d0e89f54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "label\n",
      "0    3000\n",
      "1    1000\n",
      "Name: count, dtype: int64\n",
      "Index(['filename', 'label', 'label_name', 'scene_id', 'longitude', 'latitude'], dtype='object')\n",
      "scene_id\n",
      "20180712_180429_101b      39\n",
      "20180712_180755_0f2d      38\n",
      "20161218_180845_0e26      37\n",
      "20180708_180453_0f28      36\n",
      "20170515_180653_1007      34\n",
      "                          ..\n",
      "20160905_193459_0c37       1\n",
      "20171203_185452_1_0f2b     1\n",
      "20160704_204236_0c41       1\n",
      "20171213_185421_0f3b       1\n",
      "20171023_181357_1044       1\n",
      "Name: count, Length: 434, dtype: int64\n",
      "scene_id                label\n",
      "20150718_184300_090b    0        4\n",
      "20150720_184302_0906    0        1\n",
      "20150830_000650_0b07    0        3\n",
      "20150830_000652_1_0b07  0        2\n",
      "                        1        1\n",
      "                                ..\n",
      "20180714_180427_1029    0        4\n",
      "                        1        3\n",
      "20180714_182155_1051    0        4\n",
      "                        1        2\n",
      "20180714_182329_101d    0        4\n",
      "Name: count, Length: 647, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "directory = Path(OUTPUT_PATH)\n",
    "print(directory.exists())\n",
    "print(directory.is_dir())\n",
    "\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "print(df.columns)\n",
    "print(df['scene_id'].value_counts())\n",
    "print(df.groupby('scene_id')['label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "2d6f0328-319b-4bd3-8761-5b9cedd04afb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "0\n",
      "(4000, 6)\n",
      "\n",
      "================================================================================\n",
      "1. CLASS DISTRIBUTION ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Class Distribution:\n",
      "  no-ship   :  3000  images  (75.00%)\n",
      "  ship      :  1000  images  (25.00%)\n",
      "\n",
      "Class Imbalance Ratio: 3.000000:1\n",
      "Warning: Significant class imbalance detected\n",
      "Recommendation: Considerar class weighting or data augmentation\n",
      "\n",
      " Saved visualization: class_distribution.png\n",
      "label_name\n",
      "no-ship    3000\n",
      "ship       1000\n",
      "Name: count, dtype: int64\n",
      "Index(['filename', 'label', 'label_name', 'scene_id', 'longitude', 'latitude'], dtype='object')\n",
      "0    0__20170917_190707_0f44__-122.3946224097109_37...\n",
      "Name: filename, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "#print(df)\n",
    "\n",
    "class_counts = analyze_class_distribution(df)\n",
    "print(class_counts)\n",
    "print(df.columns)\n",
    "print(df['filename'].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "522e0b81-3234-4fad-a29e-731b7b535ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NearestNeighbor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def train(self, X, y):\n",
    "        \"\"\" X is N x D where each row is an example. Y is 1-dimension of size N \"\"\"\n",
    "        # the nearest neighbor classifier simply remembers all the training data\n",
    "        self.Xtr = X\n",
    "        self.ytr = y\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" X is N X D where each row is an example we wish to predict label for \"\"\"\n",
    "        num_test = X.shape[0]\n",
    "        # lets make sure that the output type matches the input type\n",
    "        Ypred = np.zeros(num_test, dtype = self.ytr.dtype)\n",
    "\n",
    "        # loop over all test rows\n",
    "        for i in xrange(num_test):\n",
    "            # find the nearest training image to the i'th test image\n",
    "            # using the L1 distance (sum of absolute value differences)\n",
    "            distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)\n",
    "            min_index = np.argmin(distances) # get the index with smallest distance\n",
    "            Ypred[1] = self.ytr[min_index] # predict the label of the nearest example\n",
    "\n",
    "        return Ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "23ec9378-545d-4178-9bd9-2ee95e28a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#htpps://github.com/facebookresearch/faiss 'Johnson et al \"Billion-scale similarity search with GPU's\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "46b79068-665e-4e3d-bf38-807e81240ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting folium\n",
      "  Using cached folium-0.20.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting branca>=0.6.0 (from folium)\n",
      "  Downloading branca-0.8.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: jinja2>=2.9 in /home/jsancheg/git_environment/CalEnvAgency/Ships/lib/python3.12/site-packages (from folium) (3.1.6)\n",
      "Requirement already satisfied: numpy in /home/jsancheg/git_environment/CalEnvAgency/Ships/lib/python3.12/site-packages (from folium) (2.3.4)\n",
      "Requirement already satisfied: requests in /home/jsancheg/git_environment/CalEnvAgency/Ships/lib/python3.12/site-packages (from folium) (2.32.5)\n",
      "Collecting xyzservices (from folium)\n",
      "  Downloading xyzservices-2025.10.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/jsancheg/git_environment/CalEnvAgency/Ships/lib/python3.12/site-packages (from jinja2>=2.9->folium) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /home/jsancheg/git_environment/CalEnvAgency/Ships/lib/python3.12/site-packages (from requests->folium) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jsancheg/git_environment/CalEnvAgency/Ships/lib/python3.12/site-packages (from requests->folium) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/jsancheg/git_environment/CalEnvAgency/Ships/lib/python3.12/site-packages (from requests->folium) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jsancheg/git_environment/CalEnvAgency/Ships/lib/python3.12/site-packages (from requests->folium) (2025.10.5)\n",
      "Using cached folium-0.20.0-py2.py3-none-any.whl (113 kB)\n",
      "Downloading branca-0.8.2-py3-none-any.whl (26 kB)\n",
      "Downloading xyzservices-2025.10.0-py3-none-any.whl (92 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.7/92.7 kB\u001b[0m \u001b[31m148.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xyzservices, branca, folium\n",
      "Successfully installed branca-0.8.2 folium-0.20.0 xyzservices-2025.10.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/home/jsancheg/git_environment/CalEnvAgency/Ships/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4676afb-7bae-405e-aba2-5938325e3549",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ships Env Python",
   "language": "python",
   "name": "ships_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
